{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | :\u001B[43m \u001B[0m|\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Taxi-v3\")\n",
    "env.render()\n",
    "env.seed = 133\n",
    "action_size = env.action_space.n\n",
    "observation_size = env.observation_space.n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(action_size)\n",
    "print(observation_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise Q Table and other parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "q_table2 = np.zeros([observation_size, action_size])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Apply Q Learning algorithm\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "def perform_q_learning(learning_rate, discount_factor, exploration_rate, trials):\n",
    "    q_table = np.zeros([observation_size, action_size])\n",
    "    for i in range(trials):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            if random.random() <= exploration_rate:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state])\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            q_table[state, action] =   q_table[state, action] + learning_rate * (reward + discount_factor * np.max(q_table[new_state]) -\n",
    "                                                                                 q_table[state,action])\n",
    "            state = new_state\n",
    "    return q_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "def evaluate_q_table(q_table):\n",
    "    total_trip = 0\n",
    "    number_episodes = 10000\n",
    "    for _ in range(number_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        trip_length = 0\n",
    "        while not done:\n",
    "            action = np.argmax(q_table[state])\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            state = next_state\n",
    "            trip_length += 1\n",
    "        total_trip += trip_length\n",
    "    return total_trip / number_episodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "data": {
      "text/plain": "13.0755"
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = perform_q_learning(0.7, 0.9, 0.4, 10000)\n",
    "evaluate_q_table(table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "def find_optimal_values(lf=0.4, df=0.9, er=0.7, trials=5000, value=False):\n",
    "    accuracy = 10\n",
    "    trials_list_test = [(i+1)*1000 for i in range(10)]\n",
    "    learn_list = []\n",
    "    discount_list = []\n",
    "    exploration_list = []\n",
    "    trials_list = []\n",
    "    print('0%')\n",
    "    for i in range(0, accuracy):\n",
    "        learn_list.append(evaluate_q_table(perform_q_learning((i/accuracy), df, er, trials)))\n",
    "    lr = learn_list.index(min(learn_list)) / accuracy\n",
    "    print('25%')\n",
    "    for j in range(0, accuracy):\n",
    "        discount_list.append(evaluate_q_table(perform_q_learning(lf, (j/accuracy), er, trials)))\n",
    "    dr = discount_list.index(min(discount_list)) / accuracy\n",
    "    print('50%')\n",
    "    for k in range(0, accuracy):\n",
    "        exploration_list.append(evaluate_q_table(perform_q_learning(lf, df, (k/accuracy), trials)))\n",
    "    ef = exploration_list.index(min(exploration_list)) / accuracy\n",
    "    print('75%')\n",
    "    for l in trials_list_test:\n",
    "        trials_list.append(evaluate_q_table(perform_q_learning(lf, df, er, l)))\n",
    "    tf = trials_list.index(min(trials_list)) * 1000\n",
    "    print('100%')\n",
    "    if value:\n",
    "        return learn_list, discount_list, exploration_list, trials_list\n",
    "    else:\n",
    "        return lr, dr, ef, int(tf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "25%\n",
      "50%\n",
      "75%\n",
      "77.5\n",
      "80.0\n",
      "82.5\n",
      "85.0\n",
      "87.5\n",
      "90.0\n",
      "92.5\n",
      "95.0\n",
      "97.5\n",
      "100.0\n",
      "100%\n",
      "0.5 0.1 0.9 15000\n"
     ]
    }
   ],
   "source": [
    "(lf, df, er, tf) = find_optimal_values()\n",
    "print(lf, df, er, tf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "q_tables = perform_q_learning(lf, df, er, 10000)\n",
    "score = evaluate_q_table(q_tables)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.063\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def monte_carlo(learning_rate, discount_factor, exploration_rate, trials):\n",
    "    q_table = np.zeros([observation_size, action_size])\n",
    "    for i in range(trials):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        rewards = 0\n",
    "        while not done:\n",
    "            if random.random() <= exploration_rate:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state])\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            rewards += reward\n",
    "        q_table[state] = q_table[state] + learning_rate * (rewards * discount_factor - q_table[state])\n",
    "    return q_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "def find_next_action(state, exploration_rate, q_table):\n",
    "    if np.random.uniform(0, 1) < exploration_rate:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = np.argmax(q_table[state])\n",
    "    return action"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "def update_sarsa(state, state2, reward, action, action2, q_table, learning_rate, discount_rate):\n",
    "    q_current = q_table[state, action]\n",
    "    q_future = q_table[state2, action2]\n",
    "    q_table[state, action] = q_current + learning_rate * (reward + discount_rate * (q_future - q_current))\n",
    "    return q_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "def sarsa(learning_rate, discount_rate, exploration_rate, episodes):\n",
    "    q_table = np.zeros([observation_size, action_size])\n",
    "    reward2 = 0\n",
    "    for i in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        action = find_next_action(state, exploration_rate, q_table)\n",
    "        iterations = 0\n",
    "        while not done:\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            next_action = find_next_action(new_state, exploration_rate, q_table)\n",
    "            q_table = update_sarsa(state, new_state, reward, action, next_action, q_table, learning_rate, discount_rate)\n",
    "            state = new_state\n",
    "            action = next_action\n",
    "            iterations += 1\n",
    "            reward2 += 1\n",
    "    # print(reward2/episodes)\n",
    "    return q_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.7683\n"
     ]
    }
   ],
   "source": [
    "table = sarsa(0.25, 0.95, 0.2, 10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "31.3121"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_q_table(table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "def solve_sarsa_parameters(lf=0.4, df=0.9, er=0.7, trials=5000, value=False):\n",
    "    accuracy = 10\n",
    "    trials_list_test = [(i+1)*1000 for i in range(10)]\n",
    "    learn_list = []\n",
    "    discount_list = []\n",
    "    exploration_list = []\n",
    "    trials_list = []\n",
    "    print('0%')\n",
    "    for i in range(0, accuracy):\n",
    "        learn_list.append(evaluate_q_table(sarsa((i/accuracy), df, er, trials)))\n",
    "    lr = learn_list.index(min(learn_list)) / accuracy\n",
    "    print('25%')\n",
    "    for j in range(0, accuracy):\n",
    "        discount_list.append(evaluate_q_table(sarsa(lf, (j/accuracy), er, trials)))\n",
    "    dr = discount_list.index(min(discount_list)) / accuracy\n",
    "    print('50%')\n",
    "    for k in range(0, accuracy):\n",
    "        exploration_list.append(evaluate_q_table(sarsa(lf, df, (k/accuracy), trials)))\n",
    "    ef = exploration_list.index(min(exploration_list)) / accuracy\n",
    "    print('75%')\n",
    "    for l in trials_list_test:\n",
    "        trials_list.append(evaluate_q_table(sarsa(lf, df, er, l)))\n",
    "    tf = trials_list.index(min(trials_list)) * 1000\n",
    "    print('100%')\n",
    "    if value:\n",
    "        return learn_list, discount_list, exploration_list, trials_list\n",
    "    else:\n",
    "        return lr, dr, ef, int(tf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "25%\n",
      "50%\n",
      "75%\n",
      "77.5\n",
      "80.0\n",
      "82.5\n",
      "85.0\n",
      "87.5\n",
      "90.0\n",
      "92.5\n",
      "95.0\n",
      "97.5\n",
      "100.0\n",
      "100%\n"
     ]
    }
   ],
   "source": [
    "find_values = solve_sarsa_parameters(value=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([200.0, 125.3049, 97.1297, 123.2287, 84.0328, 97.6563, 103.8183, 185.4372, 158.19, 200.0], [200.0, 172.4963, 143.582, 126.3884, 107.0194, 110.5478, 96.1374, 103.3706, 70.9083, 74.0317], [13.0821, 28.2361, 18.3497, 39.6064, 66.8036, 77.8789, 26.0827, 134.0269, 68.6725, 106.6157], [161.1453, 140.0483, 138.0711, 93.5501, 83.2458, 63.7309, 75.1032, 64.1239, 65.5854, 80.6219])\n"
     ]
    },
    {
     "data": {
      "text/plain": "13.0904"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(find_values)\n",
    "evaluate_q_table(sarsa(0.4, 0.8, 0, 6000))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Graph Values for hyper-parameter testing\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "25%\n",
      "50%\n",
      "75%\n",
      "100%\n"
     ]
    }
   ],
   "source": [
    "lists = find_optimal_values(value=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([200.0, 13.0927, 13.0809, 13.0668, 13.0932, 13.0529, 13.0519, 13.0694, 13.0812, 13.0886], [200.0, 13.0591, 13.0798, 13.0826, 13.0217, 13.0442, 13.0556, 13.01, 13.1111, 13.0384], [13.0701, 13.0762, 13.0594, 13.0526, 13.0538, 13.043, 13.0895, 13.0301, 13.1039, 13.0265], [15.9158, 13.0757, 13.0677, 13.0853, 13.031, 13.0959, 13.0622, 13.0687, 13.0561, 13.0842])\n",
      "0.6\n",
      "0.7\n",
      "0.9\n",
      "20000\n",
      "13.0704\n"
     ]
    }
   ],
   "source": [
    "print(lists)\n",
    "print(np.argmin(lists[0])/ 10)\n",
    "print(np.argmin(lists[1])/ 10)\n",
    "print(np.argmin(lists[2])/ 10)\n",
    "print(np.argmin(lists[3]) * 5000)\n",
    "print(evaluate_q_table(perform_q_learning(0.3, 0.4, 0.4, 40000)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trials_list = []\n",
    "val = 0\n",
    "for l in [3**(i+2) for i in range(10)]:\n",
    "    trials_list.append(evaluate_q_table(perform_q_learning(lf, df, er, l)))\n",
    "    val+= 2.5\n",
    "    print(str(val))\n",
    "tf = trials_list.index(min(trials_list)) / 10\n",
    "print(trials_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learning_rates = lists[0]\n",
    "# Data for plotting\n",
    "t = [float(i/10) for i in range(0,10)]\n",
    "s = learning_rates\n",
    "r = lists[1]\n",
    "g = lists[2]\n",
    "b = trials_list\n",
    "print(b)\n",
    "n = []\n",
    "for i in s:\n",
    "    n.append(i+1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, s, label='Learning')\n",
    "ax.plot(t, r, label='Discount')\n",
    "ax.plot(t, g, label='Exploration')\n",
    "# ax.plot([100**(i+1) for i in range(10)], b)\n",
    "ax.plot(t, b, label='Trials')\n",
    "\n",
    "ax.set(xlabel='Learning Rate', ylabel='Number of Steps',\n",
    "       title='Learning rate vs Number of Steps')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "fig.savefig(\"trials.png\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}