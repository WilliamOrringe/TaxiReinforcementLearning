{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "import gym\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "env = gym.make(\"Taxi-v3\").env"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 1, 10)             5000      \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                550       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 306       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,956\n",
      "Trainable params: 10,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "action_size = env.action_space.n\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(500, 10, input_length=1))\n",
    "model.add(Reshape((10,)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(action_size, activation='linear'))\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute '_compile_time_distribution_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [19]\u001B[0m, in \u001B[0;36m<cell line: 10>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mdisable_eager_execution()\n\u001B[1;32m      4\u001B[0m dqn \u001B[38;5;241m=\u001B[39m DQNAgent(model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m      5\u001B[0m               nb_actions\u001B[38;5;241m=\u001B[39maction_size,\n\u001B[1;32m      6\u001B[0m               memory\u001B[38;5;241m=\u001B[39mmemory,\n\u001B[1;32m      7\u001B[0m               nb_steps_warmup\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m,\n\u001B[1;32m      8\u001B[0m               target_model_update\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;66;03m# 1e-2\u001B[39;00m\n\u001B[1;32m      9\u001B[0m               policy\u001B[38;5;241m=\u001B[39mpolicy)\n\u001B[0;32m---> 10\u001B[0m \u001B[43mdqn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mAdam\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmae\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m dqn\u001B[38;5;241m.\u001B[39mfit(env, nb_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10000\u001B[39m,\n\u001B[1;32m     12\u001B[0m        visualize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     13\u001B[0m        verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     14\u001B[0m        nb_max_episode_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m,\n\u001B[1;32m     15\u001B[0m        log_interval\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10000\u001B[39m)\n",
      "File \u001B[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/rl/agents/dqn.py:171\u001B[0m, in \u001B[0;36mDQNAgent.compile\u001B[0;34m(self, optimizer, metrics)\u001B[0m\n\u001B[1;32m    168\u001B[0m metrics \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [mean_q]  \u001B[38;5;66;03m# register default metrics\u001B[39;00m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# We never train the target model, hence we can set the optimizer and loss arbitrarily.\u001B[39;00m\n\u001B[0;32m--> 171\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_model \u001B[38;5;241m=\u001B[39m \u001B[43mclone_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcustom_model_objects\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msgd\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msgd\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/rl/util.py:15\u001B[0m, in \u001B[0;36mclone_model\u001B[0;34m(model, custom_objects)\u001B[0m\n\u001B[1;32m     10\u001B[0m config \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass_name\u001B[39m\u001B[38;5;124m'\u001B[39m: model\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfig\u001B[39m\u001B[38;5;124m'\u001B[39m: model\u001B[38;5;241m.\u001B[39mget_config(),\n\u001B[1;32m     13\u001B[0m }\n\u001B[1;32m     14\u001B[0m clone \u001B[38;5;241m=\u001B[39m model_from_config(config, custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects)\n\u001B[0;32m---> 15\u001B[0m clone\u001B[38;5;241m.\u001B[39mset_weights(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_weights\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m clone\n",
      "File \u001B[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/engine/training_v1.py:156\u001B[0m, in \u001B[0;36mModel.get_weights\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_weights\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    150\u001B[0m   \u001B[38;5;124;03m\"\"\"Retrieves the weights of the model.\u001B[39;00m\n\u001B[1;32m    151\u001B[0m \n\u001B[1;32m    152\u001B[0m \u001B[38;5;124;03m  Returns:\u001B[39;00m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;124;03m      A flat list of Numpy arrays.\u001B[39;00m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m    155\u001B[0m   strategy \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distribution_strategy \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m--> 156\u001B[0m               \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compile_time_distribution_strategy\u001B[49m)\n\u001B[1;32m    157\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m strategy:\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m strategy\u001B[38;5;241m.\u001B[39mscope():\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Sequential' object has no attribute '_compile_time_distribution_strategy'"
     ]
    }
   ],
   "source": [
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = EpsGreedyQPolicy()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "dqn = DQNAgent(model=model,\n",
    "              nb_actions=action_size,\n",
    "              memory=memory,\n",
    "              nb_steps_warmup=500,\n",
    "              target_model_update=0.01, # 1e-2\n",
    "              policy=policy)\n",
    "dqn.compile(Adam, metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=10000,\n",
    "       visualize=False,\n",
    "       verbose=1,\n",
    "       nb_max_episode_steps=20,\n",
    "       log_interval=10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load model from data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "# from IPython.display import clear_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "def _get_action_for_state(state):\n",
    "    # predicted = model.predict_on_batch(tf.expand_dims(state, axis=0))\n",
    "    predicted = model.predict(tf.expand_dims(state, axis=0))\n",
    "    print(predicted)\n",
    "    if np.random.uniform(0, 1) < 0.6:\n",
    "        action = np.random.choice([0,1,2,3,4,5])\n",
    "    else:\n",
    "        action = np.argmax(predicted)\n",
    "    return action"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001B[35m\u001B[43mR\u001B[0m\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Iter: 25 - Action: 1(North) - Reward -1\n",
      "cannot converge :(\n"
     ]
    }
   ],
   "source": [
    "sleep = 0.2\n",
    "max_steps = 25\n",
    "\n",
    "\n",
    "try:\n",
    "    actions_str = [\"South\", \"North\", \"East\", \"West\", \"Pickup\", \"Dropoff\"]\n",
    "\n",
    "    iteration = 0\n",
    "    state = env.reset()  # reset environment to a new, random state\n",
    "    env.render()\n",
    "    print(f\"Iter: {iteration} - Action: *** - Reward ***\")\n",
    "    time.sleep(sleep)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = _get_action_for_state(state)\n",
    "        iteration += 1\n",
    "        state, reward, done, info = env.step(action)\n",
    "        clear_output(wait=True)\n",
    "        env.render()\n",
    "        print(f\"Iter: {iteration} - Action: {action}({actions_str[action]}) - Reward {reward}\")\n",
    "        time.sleep(sleep)\n",
    "        if iteration == max_steps:\n",
    "            print(\"cannot converge :(\")\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}